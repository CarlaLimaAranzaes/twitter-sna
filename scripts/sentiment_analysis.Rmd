---
title: "Sentiment Analysis"
author: "Nicole Jess, Yuqing Liu"
date: "`r format(Sys.time(), '%Y-%m-%d, %H:%M:%S %Z')`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding:  hide
params: 
  outfile: "sentiment_analysis.html"
---

# Purpose


```{r global-options, include=FALSE}
# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", paste0("\n \\", options$cfsize,"\n\n", 
                                              x, "\n\n \\normalsize"), x)
  })

# Global chunk options (over-ridden by local chunk options)
knitr::opts_chunk$set(include  = TRUE, echo = TRUE, error = TRUE, 
                      message = FALSE, warning = FALSE, 
                      cfsize = "footnotesize", fig.height=8)

# Declare location of this script relative to the project root directory.
here::i_am(path = "scripts/sentiment_analysis.Rmd")
```

# Load R Packages
Load contributed R packages that we need to get additional functions. 

``` {r load-packages}
library(tidyverse)          # dplyr, ggplot2, tidyr, etc.
library(here)               # for here()
library(tidytext)           # for unnest_tokens(), get_sentiments()

```

# Load data

``` {r load-data}
# Data file created by "scripts/create_social_network_data.Rmd"
load(file=here("data/t1.RData"))
load(file=here("data/t3.RData"))

```

```{r data-prep}

# prep for sentiment analysis
t1.tweets <-  t1 %>% 
  filter(lang == "en") %>%
  select(nominator = id_str, created_at, text = full_text)

t3.tweets <-  t3 %>% 
  filter(lang == "en") %>%
  select(nominator = id_str, created_at, text = full_text)

# Exclude URL patterns in Text
t1.tweets$text <- gsub("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "" ,t3.tweets$text)

# Exclude @user patterns in Text
t1.tweets$text <- gsub("@\\w+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("@\\w+", "" ,t3.tweets$text)

# Exclude hashtags patterns in Text
t1.tweets$text <- gsub("#\\w+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("#\\w+", "" ,t3.tweets$text)

#To make each word a cell row with the corresponding nominator
t1.byword <- unnest_tokens(t1.tweets, output = word, input = text)
t3.byword <- unnest_tokens(t3.tweets, output = word, input = text)

#Exclude stop words that do not add any value nor express sentiment
stop_words <- read.csv(file = here("scripts/stopwords.csv"), header = TRUE)

t1.byword <- t1.byword %>%
  anti_join(stop_words, by = "word")
t3.byword <- t3.byword %>%
  anti_join(stop_words, by = "word")

```

```{r import-sentiments}

# select only POSITIVE words in the NRC data set
sent_pos <- get_sentiments("nrc") %>%
  filter(sentiment == "positive") %>%
  rename(pos_sentiment = sentiment)

# select only NEGATIVE words in the NRC data set
sent_neg <- get_sentiments("nrc") %>%
  filter(sentiment == "negative") %>%
  rename(neg_sentiment = sentiment)

# alternatively, upload an excel file of user defined sentiments
#sentiment <- read.csv("sentiments.csv")

#sent_pos <- sentiment %>%
#  filter(sentiment == "positive") %>%
#  rename(pos_sentiment = sentiment)
#sent_neg <- sentiment %>%
#  filter(sentiment == "negative") %>%
#  rename(neg_sentiment = sentiment)

```


```{r code-sentiments}

# Create the list of words by nominator, identifying in addition if the words are positive or negative
t1.byword <- t1.byword %>%
  left_join(sent_pos, by="word") %>%
  left_join(sent_neg, by="word") %>%
  select(nominator, created_at, word, pos_sentiment, neg_sentiment)

t3.byword <- t3.byword %>%
  left_join(sent_pos, by="word") %>%
  left_join(sent_neg, by="word") %>%
  select(nominator, created_at, word, pos_sentiment, neg_sentiment)

```

```{r sentiment-freq}

# Frequencies of positive words by nominator per tweet
t1.pos.words <- t1.byword %>%
  group_by(nominator, created_at, pos_sentiment) %>%
  summarize(pos_freq = n()) %>%
  filter(pos_sentiment=="positive")

t3.pos.words <- t3.byword %>%
  group_by(nominator, created_at, pos_sentiment) %>%
  summarize(pos_freq = n()) %>%
  filter(pos_sentiment=="positive")

# Frequencies of negative words by nominator per tweet
t1.neg.words <- t1.byword %>%
  group_by(nominator, created_at, neg_sentiment) %>%
  summarize(neg_freq = n()) %>%
  filter(neg_sentiment=="negative")

t3.neg.words <- t3.byword %>%
  group_by(nominator, created_at, neg_sentiment) %>%
  summarize(neg_freq = n()) %>%
  filter(neg_sentiment=="negative")

```

```{r}

# Total words by nominator per tweet
t1.total.words <- t1.byword %>%
  group_by(nominator, created_at) %>%
  summarize(total_words = n())

t3.total.words <- t3.byword %>%
  group_by(nominator, created_at) %>%
  summarize(total_words = n())

# join all sentiment data
t1.all.sentiment <- t1.total.words %>%
  full_join(t1.pos.words, by=c("nominator", "created_at")) %>%
  full_join(t1.neg.words, by=c("nominator", "created_at")) %>%
  mutate(pos_freq=replace_na(pos_freq,0),
         neg_freq=replace_na(neg_freq,0),
         neutral_freq=total_words-(pos_freq+neg_freq)) %>%
  select(nominator,created_at,pos_freq,neg_freq,neutral_freq,total_words)

t3.all.sentiment <- t3.total.words %>%
  full_join(t3.pos.words,by=c("nominator", "created_at")) %>%
  full_join(t3.neg.words,by=c("nominator", "created_at")) %>%
  mutate(pos_freq=replace_na(pos_freq,0),
         neg_freq=replace_na(neg_freq,0),
         neutral_freq=total_words-(pos_freq+neg_freq)) %>%
  select(nominator,created_at,pos_freq,neg_freq,neutral_freq,total_words)

```

# Save Data

```{r save-sentiment-data}
# here() creates a path relative to the location of the twitter-sna.proj file
# that will be portable across local repositories on different computers.

save(t1.all.sentiment, file=here("data/t1_sentiment.RData"))
save(t3.all.sentiment, file=here("data/t3_sentiment.RData"))


```
