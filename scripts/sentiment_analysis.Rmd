---
title: "Sentiment Analysis"
author: "Nicole Jess, Yuqing Liu"
date: "`r format(Sys.time(), '%Y-%m-%d, %H:%M:%S %Z')`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding:  hide
params: 
  outfile: "sentiment_analysis.html"
---

# Purpose


```{r global-options, include=FALSE}
# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", paste0("\n \\", options$cfsize,"\n\n", 
                                              x, "\n\n \\normalsize"), x)
  })

# Global chunk options (over-ridden by local chunk options)
knitr::opts_chunk$set(include  = TRUE, echo = TRUE, error = TRUE, 
                      message = FALSE, warning = FALSE, 
                      cfsize = "footnotesize", fig.height=8)

# Declare location of this script relative to the project root directory.
here::i_am(path = "scripts/sentiment_analysis.Rmd")
```

# Load R Packages
Load contributed R packages that we need to get additional functions. 

``` {r load-packages}
library(tidyverse)          # dplyr, ggplot2, tidyr, etc.
library(here)               # for here()

```

# Load data

``` {r load-data}
# Data file created by "scripts/create_social_network_data.Rmd"
load(file=here("data/t1.RData"))
load(file=here("data/t3.RData"))

```

```{r data-prep}

# prep for sentiment analysis
t1.tweets <-  t1 %>% 
  filter(lang == "en") %>%
  select(nominator = id_str, created_at, text = full_text)

t3.tweets <-  t3 %>% 
  filter(lang == "en") %>%
  select(nominator = id_str, created_at, text = full_text)

# Exclude URL patterns in Text
t1.tweets$text <- gsub("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "" ,t3.tweets$text)

# Exclude @user patterns in Text
t1.tweets$text <- gsub("@\\w+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("@\\w+", "" ,t3.tweets$text)

# Exclude hashtags patterns in Text
t1.tweets$text <- gsub("#\\w+", "" ,t1.tweets$text)
t3.tweets$text <- gsub("#\\w+", "" ,t3.tweets$text)

#To make each word a cell row with the corresponding nominator
t1.byword <- tidytext::unnest_tokens(t1.tweets, output = word, input = text)
t3.byword <- tidytext::unnest_tokens(t3.tweets, output = word, input = text)

```

